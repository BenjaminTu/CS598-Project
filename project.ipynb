{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, sparse\n",
    "\n",
    "audio_dir = '../GTZAN/genres_original/'\n",
    "corrupted_file = ['jazz.00054.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: blues\n",
      "Processing genre: classical\n",
      "Processing genre: country\n",
      "Processing genre: disco\n",
      "Processing genre: hiphop\n",
      "Processing genre: jazz\n",
      "Processing genre: metal\n",
      "Processing genre: pop\n",
      "Processing genre: reggae\n",
      "Processing genre: rock\n",
      "Done with preprocessing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pre processing\n",
    "genres = os.listdir(audio_dir)\n",
    "\n",
    "num_train = 90\n",
    "\n",
    "# spectrogram\n",
    "window = 'hamming'\n",
    "nperseg = 4410\n",
    "s_n_fft = 1024\n",
    "s_hop_length = 512\n",
    "\n",
    "spec_train_data = []\n",
    "spec_test_data = []\n",
    "\n",
    "spec_train_label = []\n",
    "spec_test_label = []\n",
    "spec_vote_length = []\n",
    "spec_extended_test_label = []\n",
    "\n",
    "# mfcc\n",
    "n_mfcc = 15\n",
    "\n",
    "mfcc_train_data = []\n",
    "mfcc_test_data = []\n",
    "\n",
    "mfcc_train_label = []\n",
    "mfcc_test_label = []\n",
    "mfcc_vote_length = []\n",
    "mfcc_extended_test_label = []\n",
    "\n",
    "# mel-spectrogram\n",
    "ms_n_fft = 1024\n",
    "ms_hop_length = 512\n",
    "\n",
    "mspec_train_data = []\n",
    "mspec_test_data = []\n",
    "\n",
    "mspec_train_label = []\n",
    "mspec_test_label = []\n",
    "mspec_vote_length = []\n",
    "mspec_extended_test_label = []\n",
    "\n",
    "\n",
    "for genre in genres:\n",
    "    print(\"Processing genre: \" + genre)\n",
    "    files = os.listdir(audio_dir + genre)\n",
    "    \n",
    "    # Split training and testing\n",
    "    mask = num_train * [True] + (100 - num_train) * [False]\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "    for i, file in enumerate(files):        \n",
    "        if file in corrupted_file:\n",
    "            continue\n",
    "        file_name = audio_dir + genre + '/' + file\n",
    "        sound, sample_rate = librosa.load(file_name)\n",
    "        \n",
    "        # spectrogram\n",
    "        spec = librosa.stft(y=sound, window=window, n_fft=s_n_fft, hop_length=s_hop_length)        \n",
    "        spec_sample = np.log(np.abs(spec) + 1e-7)\n",
    "\n",
    "        # mfcc \n",
    "        mfcc_sample = librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # mel-spectrogram\n",
    "        mspec = librosa.feature.melspectrogram(y=sound, sr=sample_rate, window=window, n_fft=ms_n_fft, hop_length=ms_hop_length)        \n",
    "        mspec_sample = np.log(np.abs(mspec) + 1e-7)\n",
    "        \n",
    "        if mask[i]:\n",
    "            spec_train_data.append(spec_sample)\n",
    "            mfcc_train_data.append(mfcc_sample)\n",
    "            mspec_train_data.append(mspec_sample)\n",
    "            \n",
    "            spec_train_label.extend([genres.index(genre)] * spec_sample.shape[1])\n",
    "            mfcc_train_label.extend([genres.index(genre)] * mfcc_sample.shape[1])\n",
    "            mspec_train_label.extend([genres.index(genre)] * mspec_sample.shape[1])\n",
    "\n",
    "        else:\n",
    "            spec_test_data.append(spec_sample)\n",
    "            mfcc_test_data.append(mfcc_sample)\n",
    "            mspec_test_data.append(mspec_sample)\n",
    "            \n",
    "            spec_test_label.extend([genres.index(genre)])\n",
    "            mfcc_test_label.extend([genres.index(genre)])\n",
    "            mspec_test_label.extend([genres.index(genre)])\n",
    "            \n",
    "            spec_vote_length.append(spec_sample.shape[1])\n",
    "            mfcc_vote_length.append(mfcc_sample.shape[1])\n",
    "            mspec_vote_length.append(mspec_sample.shape[1])\n",
    "\n",
    "            spec_extended_test_label.extend([genres.index(genre)] * spec_sample.shape[1])\n",
    "            mfcc_extended_test_label.extend([genres.index(genre)] * mfcc_sample.shape[1])\n",
    "            mspec_extended_test_label.extend([genres.index(genre)] * mspec_sample.shape[1])\n",
    "            \n",
    "# numpyify array\n",
    "spec_train_data = np.hstack(spec_train_data)\n",
    "mfcc_train_data = np.hstack(mfcc_train_data)\n",
    "mspec_train_data = np.hstack(mspec_train_data)\n",
    "\n",
    "spec_test_data = np.hstack(spec_test_data)\n",
    "mfcc_test_data = np.hstack(mfcc_test_data)\n",
    "mspec_test_data = np.hstack(mspec_test_data)\n",
    "\n",
    "spec_train_label = np.array(spec_train_label)\n",
    "mfcc_train_label = np.array(mfcc_train_label)\n",
    "mspec_train_label = np.array(mspec_train_label)\n",
    "\n",
    "spec_test_label = np.array(spec_test_label)\n",
    "mfcc_test_label = np.array(mfcc_test_label)\n",
    "mspec_test_label = np.array(mspec_test_label)\n",
    "\n",
    "spec_vote_length = np.array(spec_vote_length)\n",
    "mfcc_vote_length = np.array(mfcc_vote_length)\n",
    "mspec_vote_length = np.array(mspec_vote_length)\n",
    "\n",
    "spec_extended_test_label = np.array(spec_extended_test_label)\n",
    "mfcc_extended_test_label = np.array(mfcc_extended_test_label)\n",
    "mspec_extended_test_label = np.array(mspec_extended_test_label)\n",
    "\n",
    "\n",
    "# 0 mean\n",
    "\n",
    "# spectrogram\n",
    "spec_scaler = StandardScaler()\n",
    "spec_scaler.fit(spec_train_data.T)\n",
    "spec_train_data = spec_scaler.transform(spec_train_data.T)\n",
    "spec_test_data = spec_scaler.transform(spec_test_data.T)\n",
    "\n",
    "# mfcc\n",
    "mfcc_scaler = StandardScaler()\n",
    "mfcc_scaler.fit(mfcc_train_data.T)\n",
    "mfcc_train_data = mfcc_scaler.transform(mfcc_train_data.T)\n",
    "mfcc_test_data = mfcc_scaler.transform(mfcc_test_data.T)\n",
    "\n",
    "# mel-spectrogram\n",
    "mspec_scaler = StandardScaler()\n",
    "mspec_scaler.fit(mspec_train_data.T)\n",
    "mspec_train_data = mspec_scaler.transform(mspec_train_data.T)\n",
    "mspec_test_data = mspec_scaler.transform(mspec_test_data.T)\n",
    "\n",
    "print('Done with preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "n_components = 15\n",
    "\n",
    "# spectrogram\n",
    "spec_pca = PCA(n_components=n_components)\n",
    "spec_pca.fit(spec_train_data)\n",
    "spec_X_train = spec_pca.transform(spec_train_data)\n",
    "spec_X_test = spec_pca.transform(spec_test_data)\n",
    "\n",
    "# mfcc \n",
    "mfcc_pca = PCA(n_components=n_components)\n",
    "mfcc_pca.fit(mfcc_train_data)\n",
    "mfcc_X_train = mfcc_pca.transform(mfcc_train_data)\n",
    "mfcc_X_test = mfcc_pca.transform(mfcc_test_data)\n",
    "\n",
    "# melspectrogram\n",
    "mspec_pca = PCA(n_components=n_components)\n",
    "mspec_pca.fit(mspec_train_data)\n",
    "mspec_X_train = mspec_pca.transform(mspec_train_data)\n",
    "mspec_X_test = mspec_pca.transform(mspec_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blues\n",
      "1 classical\n",
      "2 country\n",
      "3 disco\n",
      "4 hiphop\n",
      "5 jazz\n",
      "6 metal\n",
      "7 pop\n",
      "8 reggae\n",
      "9 rock\n"
     ]
    }
   ],
   "source": [
    "for i, genre in enumerate(genres):\n",
    "    print (str(i) + ' ' + genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.393 0.323 0.516 0.748 0.725 0.651 0.618 0.583 0.306 0.338 0.783 0.926\n",
      " 0.372 0.252 0.968 0.906 0.838 0.677 0.981 0.621 0.320 0.450 0.245 0.285\n",
      " 0.204 0.301 0.271 0.253 0.247 0.351 0.288 0.348 0.508 0.236 0.457 0.311\n",
      " 0.383 0.267 0.319 0.391 0.343 0.239 0.465 0.556 0.327 0.260 0.266 0.445\n",
      " 0.429 0.299 0.461 0.741 0.806 0.382 0.923 0.920 0.266 0.488 0.870 0.439\n",
      " 0.951 0.940 0.974 0.886 0.725 1.000 1.000 0.681 0.825 0.565 0.660 0.619\n",
      " 0.855 0.637 0.589 0.471 0.725 0.264 0.456 0.606 0.188 0.186 0.236 0.403\n",
      " 0.358 0.298 0.304 0.243 0.360 0.350 0.338 0.390 0.268 0.725 0.241 0.196\n",
      " 0.544 0.377 0.226 0.327]\n",
      "voting accuracy: \n",
      "0.68\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50     12930\n",
      "           1       0.76      0.73      0.75     12936\n",
      "           2       0.32      0.27      0.29     12933\n",
      "           3       0.31      0.26      0.29     12936\n",
      "           4       0.32      0.25      0.28     12971\n",
      "           5       0.44      0.63      0.52     12950\n",
      "           6       0.65      0.85      0.74     12930\n",
      "           7       0.44      0.57      0.50     12930\n",
      "           8       0.30      0.23      0.26     12930\n",
      "           9       0.20      0.19      0.20     12930\n",
      "\n",
      "    accuracy                           0.45    129376\n",
      "   macro avg       0.43      0.45      0.43    129376\n",
      "weighted avg       0.43      0.45      0.43    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(spec_X_train, spec_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(spec_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(spec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+spec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / spec_vote_length[i])\n",
    "    cur_idx = cur_idx + spec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == spec_test_label) / spec_test_label.shape[0])\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(spec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.297 0.367 0.837 0.838 0.781 0.668 0.811 0.438 0.341 0.343 0.888 0.847\n",
      " 0.645 0.429 0.947 0.909 0.898 0.866 0.962 0.616 0.379 0.393 0.268 0.231\n",
      " 0.228 0.256 0.271 0.284 0.267 0.448 0.324 0.346 0.386 0.195 0.486 0.358\n",
      " 0.447 0.330 0.428 0.464 0.271 0.216 0.371 0.577 0.333 0.296 0.275 0.483\n",
      " 0.442 0.346 0.456 0.658 0.727 0.581 0.995 0.997 0.247 0.732 0.995 0.439\n",
      " 0.941 0.885 0.962 0.801 0.539 1.000 1.000 0.392 0.762 0.531 0.715 0.606\n",
      " 0.961 0.729 0.601 0.510 0.749 0.292 0.644 0.680 0.212 0.288 0.300 0.486\n",
      " 0.567 0.408 0.418 0.244 0.425 0.394 0.229 0.317 0.259 0.539 0.237 0.205\n",
      " 0.439 0.227 0.393 0.212]\n",
      "voting accuracy: \n",
      "0.74\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.57     12930\n",
      "           1       0.75      0.80      0.77     12936\n",
      "           2       0.29      0.27      0.28     12933\n",
      "           3       0.33      0.31      0.32     12936\n",
      "           4       0.37      0.25      0.30     12971\n",
      "           5       0.52      0.68      0.59     12950\n",
      "           6       0.70      0.78      0.74     12930\n",
      "           7       0.46      0.63      0.53     12930\n",
      "           8       0.39      0.29      0.33     12930\n",
      "           9       0.22      0.20      0.21     12930\n",
      "\n",
      "    accuracy                           0.48    129376\n",
      "   macro avg       0.46      0.48      0.46    129376\n",
      "weighted avg       0.46      0.48      0.46    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mfcc_X_train, mfcc_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mfcc_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mfcc_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mfcc_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mfcc_vote_length[i])\n",
    "    cur_idx = cur_idx + mfcc_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == mfcc_test_label) / mfcc_test_label.shape[0])\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mfcc_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.254 0.248 0.405 0.790 0.795 0.708 0.617 0.466 0.290 0.305 0.760 0.898\n",
      " 0.475 0.222 0.940 0.872 0.778 0.732 0.940 0.545 0.363 0.505 0.329 0.331\n",
      " 0.233 0.252 0.342 0.271 0.224 0.387 0.313 0.327 0.517 0.243 0.404 0.340\n",
      " 0.343 0.278 0.315 0.366 0.288 0.200 0.396 0.425 0.340 0.258 0.252 0.437\n",
      " 0.483 0.333 0.644 0.716 0.755 0.524 0.968 0.961 0.206 0.765 0.854 0.467\n",
      " 0.951 0.916 0.968 0.812 0.661 1.000 1.000 0.575 0.816 0.493 0.615 0.511\n",
      " 0.898 0.603 0.530 0.435 0.675 0.346 0.459 0.514 0.173 0.265 0.249 0.367\n",
      " 0.460 0.352 0.318 0.300 0.412 0.235 0.282 0.495 0.304 0.661 0.301 0.202\n",
      " 0.440 0.323 0.215 0.281]\n",
      "voting accuracy: \n",
      "0.64\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.48     12930\n",
      "           1       0.76      0.72      0.74     12936\n",
      "           2       0.30      0.27      0.28     12933\n",
      "           3       0.29      0.26      0.28     12936\n",
      "           4       0.35      0.26      0.30     12971\n",
      "           5       0.50      0.69      0.58     12950\n",
      "           6       0.64      0.82      0.72     12930\n",
      "           7       0.43      0.53      0.47     12930\n",
      "           8       0.33      0.25      0.29     12930\n",
      "           9       0.21      0.20      0.21     12930\n",
      "\n",
      "    accuracy                           0.44    129376\n",
      "   macro avg       0.43      0.44      0.43    129376\n",
      "weighted avg       0.43      0.44      0.43    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mspec_X_train, mspec_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mspec_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mspec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mspec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mspec_vote_length[i])\n",
    "    cur_idx = cur_idx + mspec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == mspec_test_label) / mspec_test_label.shape[0])\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mspec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "[LibSVM]Predicting...\n",
      "confidence: \n",
      "[0.394 0.455 0.529 0.812 0.807 0.772 0.737 0.618 0.396 0.425 0.847 0.956\n",
      " 0.558 0.415 0.986 0.954 0.911 0.654 0.999 0.720 0.538 0.520 0.284 0.394\n",
      " 0.228 0.412 0.344 0.336 0.283 0.520 0.407 0.576 0.715 0.387 0.641 0.476\n",
      " 0.466 0.377 0.394 0.501 0.492 0.266 0.515 0.726 0.474 0.469 0.261 0.366\n",
      " 0.516 0.365 0.514 0.797 0.828 0.383 0.824 0.641 0.261 0.461 0.879 0.372\n",
      " 0.971 0.963 0.990 0.910 0.657 0.850 0.811 0.747 0.954 0.572 0.840 0.883\n",
      " 0.873 0.843 0.796 0.548 0.830 0.415 0.780 0.831 0.229 0.263 0.316 0.582\n",
      " 0.422 0.377 0.585 0.344 0.597 0.436 0.329 0.570 0.431 0.657 0.288 0.307\n",
      " 0.637 0.596 0.321 0.288]\n",
      "voting accuracy: \n",
      "0.68\n",
      "non-voting accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.55     12930\n",
      "           1       0.77      0.78      0.77     12936\n",
      "           2       0.34      0.33      0.33     12933\n",
      "           3       0.41      0.34      0.37     12936\n",
      "           4       0.41      0.24      0.30     12971\n",
      "           5       0.46      0.59      0.52     12950\n",
      "           6       0.71      0.84      0.77     12930\n",
      "           7       0.42      0.73      0.53     12930\n",
      "           8       0.36      0.28      0.32     12930\n",
      "           9       0.23      0.16      0.19     12930\n",
      "\n",
      "    accuracy                           0.48    129376\n",
      "   macro avg       0.47      0.48      0.47    129376\n",
      "weighted avg       0.47      0.48      0.47    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "svm_model = svm.SVC(gamma='scale', verbose=True)\n",
    "svm_model.fit(spec_X_train, spec_train_label)\n",
    "\n",
    "print('Predicting...')\n",
    "y_predict = svm_model.predict(spec_X_test)\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(spec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+spec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / spec_vote_length[i])\n",
    "    cur_idx = cur_idx + spec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == spec_test_label) / spec_test_label.shape[0])\n",
    "\n",
    "print(\"non-voting accuracy:\")\n",
    "print(classification_report(spec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "[LibSVM]Predicting...\n",
      "confidence: \n",
      "[0.531 0.537 0.918 0.910 0.867 0.771 0.835 0.507 0.513 0.524 0.903 0.951\n",
      " 0.602 0.473 0.975 0.875 0.856 0.804 0.993 0.826 0.569 0.531 0.363 0.359\n",
      " 0.253 0.305 0.432 0.370 0.403 0.606 0.434 0.570 0.585 0.276 0.500 0.439\n",
      " 0.507 0.409 0.615 0.534 0.418 0.383 0.491 0.679 0.376 0.416 0.381 0.547\n",
      " 0.510 0.394 0.519 0.704 0.821 0.476 0.930 0.951 0.231 0.540 0.916 0.502\n",
      " 0.951 0.918 0.985 0.819 0.660 0.810 0.780 0.416 0.892 0.523 0.851 0.829\n",
      " 0.852 0.876 0.729 0.589 0.831 0.421 0.875 0.783 0.236 0.353 0.407 0.715\n",
      " 0.631 0.505 0.599 0.318 0.479 0.435 0.340 0.548 0.306 0.660 0.316 0.257\n",
      " 0.412 0.339 0.241 0.193]\n",
      "voting accuracy: \n",
      "0.7\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63     12930\n",
      "           1       0.81      0.83      0.82     12936\n",
      "           2       0.34      0.34      0.34     12933\n",
      "           3       0.40      0.37      0.38     12936\n",
      "           4       0.41      0.32      0.36     12971\n",
      "           5       0.59      0.65      0.62     12950\n",
      "           6       0.74      0.78      0.76     12930\n",
      "           7       0.47      0.73      0.57     12930\n",
      "           8       0.42      0.36      0.39     12930\n",
      "           9       0.24      0.16      0.19     12930\n",
      "\n",
      "    accuracy                           0.52    129376\n",
      "   macro avg       0.50      0.52      0.51    129376\n",
      "weighted avg       0.50      0.52      0.51    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "svm_model = svm.SVC(gamma='scale', verbose=True)\n",
    "svm_model.fit(mfcc_X_train, mfcc_train_label)\n",
    "\n",
    "print('Predicting...')\n",
    "y_predict = svm_model.predict(mfcc_X_test)\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mfcc_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mfcc_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mfcc_vote_length[i])\n",
    "    cur_idx = cur_idx + mfcc_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == mfcc_test_label) / mfcc_test_label.shape[0])\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mfcc_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "[LibSVM]Predicting...\n",
      "confidence: \n",
      "[0.311 0.393 0.578 0.872 0.896 0.866 0.768 0.510 0.374 0.387 0.807 0.937\n",
      " 0.538 0.234 0.976 0.953 0.836 0.758 0.971 0.587 0.620 0.627 0.271 0.490\n",
      " 0.322 0.346 0.467 0.324 0.274 0.470 0.453 0.557 0.720 0.379 0.612 0.441\n",
      " 0.452 0.329 0.351 0.473 0.384 0.232 0.485 0.672 0.464 0.448 0.282 0.357\n",
      " 0.480 0.346 0.701 0.695 0.828 0.410 0.634 0.562 0.226 0.647 0.690 0.374\n",
      " 0.976 0.955 0.972 0.867 0.695 0.937 0.754 0.616 0.910 0.520 0.826 0.810\n",
      " 0.819 0.829 0.740 0.625 0.809 0.376 0.809 0.753 0.202 0.262 0.428 0.533\n",
      " 0.526 0.424 0.438 0.490 0.594 0.450 0.292 0.717 0.339 0.695 0.328 0.261\n",
      " 0.533 0.533 0.281 0.303]\n",
      "voting accuracy: \n",
      "0.69\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55     12930\n",
      "           1       0.74      0.76      0.75     12936\n",
      "           2       0.34      0.36      0.35     12933\n",
      "           3       0.38      0.31      0.34     12936\n",
      "           4       0.44      0.26      0.33     12971\n",
      "           5       0.50      0.58      0.53     12950\n",
      "           6       0.70      0.82      0.76     12930\n",
      "           7       0.42      0.71      0.53     12930\n",
      "           8       0.37      0.29      0.32     12930\n",
      "           9       0.23      0.17      0.19     12930\n",
      "\n",
      "    accuracy                           0.48    129376\n",
      "   macro avg       0.47      0.48      0.47    129376\n",
      "weighted avg       0.47      0.48      0.47    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "svm_model = svm.SVC(gamma='scale', verbose=True)\n",
    "svm_model.fit(mspec_X_train, mspec_train_label)\n",
    "\n",
    "print('Predicting...')\n",
    "y_predict = svm_model.predict(mspec_X_test)\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mspec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mspec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mspec_vote_length[i])\n",
    "    cur_idx = cur_idx + mspec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(np.sum(voted_label == mspec_test_label) / mspec_test_label.shape[0])\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mspec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-supervised KNN\n",
    "\n",
    "k = 10\n",
    "\n",
    "# Spectrogram\n",
    "\n",
    "# separate labeled and unlabeled train data\n",
    "labeled_percentage = 0.1\n",
    "num_true = int(spec_X_train.shape[0] * labeled_percentage)\n",
    "num_false = spec_X_train.shape[0] - num_true\n",
    "labeled_mask = np.array(num_true * [True] + num_false * [False])\n",
    "np.random.shuffle(labeled_mask)\n",
    "\n",
    "spec_labeled_train_data = spec_X_train[labeled_mask,:]\n",
    "spec_labeled_train_label = spec_train_label[labeled_mask]\n",
    "\n",
    "spec_unlabeled_train_data = spec_X_train[~labeled_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "# Labeling unlabeled train data\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(spec_labeled_train_data, spec_labeled_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(spec_unlabeled_train_data)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.380 0.254 0.421 0.709 0.663 0.599 0.607 0.789 0.391 0.451 0.798 0.947\n",
      " 0.363 0.243 0.981 0.922 0.862 0.703 0.998 0.576 0.353 0.445 0.335 0.330\n",
      " 0.256 0.255 0.275 0.369 0.369 0.248 0.316 0.308 0.598 0.248 0.555 0.316\n",
      " 0.445 0.247 0.404 0.346 0.367 0.358 0.498 0.629 0.286 0.273 0.284 0.353\n",
      " 0.444 0.248 0.430 0.735 0.829 0.432 0.783 0.758 0.235 0.334 0.804 0.424\n",
      " 0.981 0.964 0.988 0.927 0.885 0.924 0.845 0.794 0.951 0.728 0.675 0.677\n",
      " 0.760 0.705 0.609 0.558 0.753 0.341 0.538 0.592 0.252 0.250 0.381 0.305\n",
      " 0.255 0.229 0.315 0.220 0.373 0.333 0.414 0.466 0.364 0.885 0.244 0.231\n",
      " 0.647 0.372 0.338 0.415]\n",
      "voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.30      1.00      0.46         3\n",
      "           3       0.20      0.67      0.31         3\n",
      "           4       0.40      0.67      0.50         6\n",
      "           5       1.00      0.50      0.67        20\n",
      "           6       1.00      0.59      0.74        17\n",
      "           7       0.90      0.43      0.58        21\n",
      "           8       0.20      0.67      0.31         3\n",
      "           9       0.30      0.38      0.33         8\n",
      "\n",
      "    accuracy                           0.59       100\n",
      "   macro avg       0.59      0.66      0.55       100\n",
      "weighted avg       0.78      0.59      0.63       100\n",
      "\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.42      0.45     12930\n",
      "           1       0.72      0.73      0.73     12936\n",
      "           2       0.29      0.22      0.25     12933\n",
      "           3       0.34      0.23      0.28     12936\n",
      "           4       0.34      0.22      0.27     12971\n",
      "           5       0.36      0.58      0.44     12950\n",
      "           6       0.59      0.90      0.71     12930\n",
      "           7       0.44      0.59      0.50     12930\n",
      "           8       0.28      0.16      0.20     12930\n",
      "           9       0.20      0.19      0.20     12930\n",
      "\n",
      "    accuracy                           0.42    129376\n",
      "   macro avg       0.40      0.42      0.40    129376\n",
      "weighted avg       0.40      0.42      0.40    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec_semi_train_data = np.concatenate((spec_labeled_train_data, spec_unlabeled_train_data))\n",
    "spec_semi_train_label = np.concatenate((spec_labeled_train_label, y_predict))\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(spec_semi_train_data, spec_semi_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(spec_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(spec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+spec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / spec_vote_length[i])\n",
    "    cur_idx = cur_idx + spec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(classification_report(voted_label, spec_test_label))\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(spec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-supervised KNN\n",
    "\n",
    "# MFCC\n",
    "\n",
    "# separate labeled and unlabeled train data\n",
    "labeled_percentage = 0.1\n",
    "num_true = int(mfcc_X_train.shape[0] * labeled_percentage)\n",
    "num_false = mfcc_X_train.shape[0] - num_true\n",
    "labeled_mask = np.array(num_true * [True] + num_false * [False])\n",
    "np.random.shuffle(labeled_mask)\n",
    "\n",
    "mfcc_labeled_train_data = mfcc_X_train[labeled_mask,:]\n",
    "mfcc_labeled_train_label = mfcc_train_label[labeled_mask]\n",
    "\n",
    "mfcc_unlabeled_train_data = mfcc_X_train[~labeled_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Labeling unlabeled train data\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mfcc_labeled_train_data, mfcc_labeled_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mfcc_unlabeled_train_data)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.251 0.304 0.763 0.824 0.813 0.649 0.812 0.528 0.482 0.278 0.899 0.909\n",
      " 0.798 0.491 0.981 0.954 0.960 0.928 0.978 0.582 0.312 0.348 0.305 0.243\n",
      " 0.216 0.309 0.261 0.348 0.325 0.427 0.428 0.341 0.397 0.233 0.394 0.476\n",
      " 0.512 0.351 0.382 0.390 0.265 0.291 0.376 0.663 0.314 0.381 0.233 0.384\n",
      " 0.462 0.333 0.537 0.694 0.769 0.633 0.917 0.944 0.356 0.573 0.848 0.548\n",
      " 0.979 0.942 0.981 0.865 0.613 0.833 0.787 0.495 0.886 0.591 0.774 0.698\n",
      " 0.853 0.813 0.676 0.592 0.782 0.333 0.686 0.723 0.162 0.171 0.286 0.405\n",
      " 0.506 0.347 0.489 0.248 0.479 0.430 0.256 0.464 0.316 0.613 0.209 0.273\n",
      " 0.532 0.325 0.563 0.277]\n",
      "voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82         7\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       0.20      0.50      0.29         4\n",
      "           3       0.40      0.80      0.53         5\n",
      "           4       0.30      0.75      0.43         4\n",
      "           5       1.00      0.50      0.67        20\n",
      "           6       1.00      0.77      0.87        13\n",
      "           7       0.90      0.41      0.56        22\n",
      "           8       0.40      0.80      0.53         5\n",
      "           9       0.30      0.33      0.32         9\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.62      0.68      0.60       100\n",
      "weighted avg       0.77      0.62      0.64       100\n",
      "\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56     12930\n",
      "           1       0.67      0.85      0.75     12936\n",
      "           2       0.29      0.22      0.25     12933\n",
      "           3       0.34      0.27      0.30     12936\n",
      "           4       0.41      0.21      0.28     12971\n",
      "           5       0.43      0.68      0.53     12950\n",
      "           6       0.64      0.80      0.71     12930\n",
      "           7       0.44      0.67      0.53     12930\n",
      "           8       0.43      0.22      0.29     12930\n",
      "           9       0.21      0.21      0.21     12930\n",
      "\n",
      "    accuracy                           0.46    129376\n",
      "   macro avg       0.45      0.46      0.44    129376\n",
      "weighted avg       0.45      0.46      0.44    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mfcc_semi_train_data = np.concatenate((mfcc_labeled_train_data, mfcc_unlabeled_train_data))\n",
    "mfcc_semi_train_label = np.concatenate((mfcc_labeled_train_label, y_predict))\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mfcc_semi_train_data, mfcc_semi_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mfcc_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mfcc_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mfcc_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mfcc_vote_length[i])\n",
    "    cur_idx = cur_idx + mfcc_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(classification_report(voted_label, mfcc_test_label))\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mfcc_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-supervised KNN\n",
    "\n",
    "# Mel-spectrogram\n",
    "\n",
    "# separate labeled and unlabeled train data\n",
    "labeled_percentage = 0.1\n",
    "num_true = int(mspec_X_train.shape[0] * labeled_percentage)\n",
    "num_false = mspec_X_train.shape[0] - num_true\n",
    "labeled_mask = np.array(num_true * [True] + num_false * [False])\n",
    "np.random.shuffle(labeled_mask)\n",
    "\n",
    "mspec_labeled_train_data = mspec_X_train[labeled_mask,:]\n",
    "mspec_labeled_train_label = mspec_train_label[labeled_mask]\n",
    "\n",
    "mspec_unlabeled_train_data = mspec_X_train[~labeled_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Labeling unlabeled train data\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mspec_labeled_train_data, mspec_labeled_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mspec_unlabeled_train_data)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Predicting...\n",
      "confidence: \n",
      "[0.254 0.210 0.426 0.780 0.776 0.693 0.625 0.679 0.560 0.370 0.797 0.929\n",
      " 0.568 0.227 0.987 0.881 0.830 0.763 0.986 0.537 0.455 0.561 0.350 0.338\n",
      " 0.200 0.278 0.309 0.381 0.322 0.316 0.363 0.362 0.572 0.295 0.474 0.418\n",
      " 0.408 0.282 0.400 0.381 0.296 0.292 0.422 0.525 0.358 0.251 0.211 0.421\n",
      " 0.526 0.336 0.673 0.753 0.809 0.504 0.671 0.656 0.219 0.530 0.649 0.432\n",
      " 0.979 0.957 0.987 0.898 0.836 0.954 0.797 0.718 0.942 0.651 0.584 0.555\n",
      " 0.735 0.626 0.481 0.531 0.677 0.404 0.465 0.476 0.189 0.186 0.245 0.290\n",
      " 0.361 0.288 0.324 0.343 0.459 0.214 0.397 0.514 0.362 0.836 0.341 0.224\n",
      " 0.462 0.362 0.270 0.340]\n",
      "voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59         7\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.40      0.50      0.44         8\n",
      "           3       0.20      1.00      0.33         2\n",
      "           4       0.40      0.80      0.53         5\n",
      "           5       0.90      0.53      0.67        17\n",
      "           6       1.00      0.62      0.77        16\n",
      "           7       0.90      0.45      0.60        20\n",
      "           8       0.30      0.60      0.40         5\n",
      "           9       0.30      0.27      0.29        11\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.58      0.65      0.56       100\n",
      "weighted avg       0.71      0.58      0.60       100\n",
      "\n",
      "non-voting accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.41      0.44     12930\n",
      "           1       0.70      0.75      0.72     12936\n",
      "           2       0.27      0.24      0.25     12933\n",
      "           3       0.32      0.24      0.28     12936\n",
      "           4       0.38      0.24      0.30     12971\n",
      "           5       0.43      0.59      0.49     12950\n",
      "           6       0.57      0.87      0.69     12930\n",
      "           7       0.40      0.51      0.45     12930\n",
      "           8       0.32      0.19      0.24     12930\n",
      "           9       0.20      0.20      0.20     12930\n",
      "\n",
      "    accuracy                           0.42    129376\n",
      "   macro avg       0.41      0.42      0.41    129376\n",
      "weighted avg       0.41      0.42      0.41    129376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mspec_semi_train_data = np.concatenate((mspec_labeled_train_data, mspec_unlabeled_train_data))\n",
    "mspec_semi_train_label = np.concatenate((mspec_labeled_train_label, y_predict))\n",
    "\n",
    "print('Training...')\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(mspec_semi_train_data, mspec_semi_train_label) \n",
    "print('Predicting...')\n",
    "y_predict = knn.predict(mspec_X_test)\n",
    "\n",
    "\n",
    "cur_idx = 0\n",
    "confidence = []\n",
    "voted_label = []\n",
    "for i in range(len(mspec_test_label)):\n",
    "    c = Counter(y_predict[cur_idx : cur_idx+mspec_vote_length[i]])\n",
    "    voted_label.append(c.most_common(1)[0][0])\n",
    "    confidence.append(c.most_common(1)[0][1] / mspec_vote_length[i])\n",
    "    cur_idx = cur_idx + mspec_vote_length[i]\n",
    "\n",
    "print('confidence: ')\n",
    "print(np.array(confidence))\n",
    "\n",
    "print('voting accuracy: ')\n",
    "print(classification_report(voted_label, mspec_test_label))\n",
    "\n",
    "print('non-voting accuracy: ')\n",
    "print(classification_report(mspec_extended_test_label, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
